{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction and creation of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from music21 import *\n",
    "import glob\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras as keras\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import random\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "This function extract the features from the MIDI files.\n",
    "\n",
    "Input : Directory containing the midi files\n",
    "outputs : numpy ndarray containing numpy arrays of the concatenated elements of the MIDI files.\n",
    "          Elements are feature extracted from the MIDI files.\n",
    "\"\"\"\n",
    "def read_midi_dataset(file): \n",
    "    notes = list()\n",
    "    for midi in glob.glob(file):\n",
    "        notes_to_parse = None\n",
    "        mu = converter.parse(midi)\n",
    "        s2 = instrument.partitionByInstrument(mu)\n",
    "        notes_to_parse = s2.parts[0].recurse() # parts[0] means we only takes into account piano\n",
    "        notes_song = list()\n",
    "        for element in notes_to_parse:\n",
    "            \n",
    "            if isinstance(element, note.Note): # isinstance check if element is a note\n",
    "                notes_song.append(str(element.pitch))\n",
    "\n",
    "            elif isinstance(element, chord.Chord): # check if it is a chord\n",
    "                notes_song.append('.'.join(str(n) for n in element.normalOrder))   \n",
    "            \n",
    "            elif isinstance(element, note.Rest):\n",
    "                notes.append(str(element.name)  + \" \" + str(element.quarterLength))\n",
    "            \n",
    "        notes.append(notes_song)\n",
    "\n",
    "    return np.array(notes)\n",
    "\n",
    "file = \"/home/cj/Bureau/Master2/Q2/deep_learning/project/dataset dungeon/*.mid\"\n",
    "data_elements = read_midi_dataset(file)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "This function transforms a numpy ndarray containaing arrays of elements of MIDI files into one list of\n",
    "these elements. Example : [[a,b][c,d]] => [a,b,c,d]\n",
    "\"\"\"\n",
    "def from_ndarrays_to_list(data):\n",
    "    return [element for elements_ in data for element in elements_] \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "This function shows an histogram of the notes and prints the total number of notes as well as the number\n",
    "of unique notes.\n",
    "\n",
    "Input : numpy ndarray containing numpy arrays of the concatenated elements of the MIDI files.\n",
    "Output : No output. \n",
    "\"\"\"\n",
    "\n",
    "def data_exploration(data, printt=False, show=False):\n",
    "    elements_list = from_ndarrays_to_list(data)\n",
    "    unique_elements = list(set(elements_list))\n",
    "    frequence_of_elements = dict(Counter(elements_list))\n",
    "    \n",
    "    if printt is True:\n",
    "        print(\"The number of notes in the dataset is {}.\".format(len(elements_list)))\n",
    "        print(\"The number of different notes in the dataset is {}.\".format(len(unique_elements)))\n",
    "     \n",
    "    if show is True : # histogram of the notes\n",
    "        plt.bar(list(frequence_of_elements.keys()), frequence_of_elements.values(), color='g')\n",
    "        plt.show()\n",
    "        \n",
    "data_exploration(data_elements, printt=False, show=False)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "This function deletes from the dataset elements that do not appear more than a particular frequency.\n",
    "It is a filter.\n",
    "Input : numpy ndarray containing numpy arrays of the concatenated elements of the MIDI files.\n",
    "Output : List of list. Each list is a concatenation of all the elements of a MIDI file.\n",
    "\"\"\"\n",
    "def select_notes(data, frequency, printt=False):\n",
    "    elements_list = from_ndarrays_to_list(data)\n",
    "    frequence_of_notes = dict(Counter(elements_list))\n",
    "    # unique_elements is the sorted set of unique elements of the set of MIDI files. The elements selected depends\n",
    "    # on a particular frequency. Therefore, it is the total vacabulary of the dataset.\n",
    "    unique_elements = sorted([elements_list for elements_list,\n",
    "                              count in frequence_of_notes.items() if count>=frequency])\n",
    "\n",
    "    if printt is True :\n",
    "        print(\"The number of different notes that appear at least {} time is {}.\".format(frequency,\n",
    "                                                                                     len(unique_elements)))\n",
    "    new_data = list()\n",
    "    for elements_ in data:\n",
    "        temp = list()\n",
    "        for element in elements_:\n",
    "            if element in unique_elements:\n",
    "                temp.append(element)\n",
    "        new_data.append(temp)\n",
    "        \n",
    "    return new_data\n",
    "\n",
    "freq = 0\n",
    "data_filtered = select_notes(data_elements, frequency=freq)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "This function creates the X and y matrices needed by the model.\n",
    "We use a sliding window mechanism in order to create this dataset.\n",
    "[a,b,c,d,e,f,g] becomes x1=[a,b,c], y1=[d] then x2=[b,c,d], y2=[e] etc.\n",
    "\n",
    "Input : List of list. Each list is a concatenation of all the elements of a MIDI file.\n",
    "Output : matrix X and vector y.\n",
    "\"\"\"\n",
    "def create_dataset(data, window): #time_step = window\n",
    "    x = list()\n",
    "    y = list()\n",
    "    for elements_ in data:\n",
    "        for i in range(len(elements_)-window):\n",
    "            x.append(elements_[i:i + window])\n",
    "            y.append(elements_[i + window])\n",
    "    \n",
    "    return np.array(x), np.array(y)\n",
    "\n",
    "window_size = 100\n",
    "X, y = create_dataset(data_filtered, window_size)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "This function makes the different matrices usable by an LSTM unit.\n",
    "input : For X matrices : [nb_samples, window_size]\n",
    "        For y matrices : [nb_samples, ]\n",
    "output : For X matrices : [nb_samples, window_size, 1] # 1 because there is only one feature (element)\n",
    "         For y matrices : [nb_samples, vocabulary_size] # One-hot encoding\n",
    "\"\"\"\n",
    "def reshape(X_train, X_test, y_train, y_test, size_vocab):\n",
    "    y_train = keras.utils.np_utils.to_categorical(y_train, num_classes = size_vocab)\n",
    "    y_test = keras.utils.np_utils.to_categorical(y_test, num_classes = size_vocab)\n",
    "    X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))/float(size_vocab) # Normalization\n",
    "    X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))/float(size_vocab) # Normalization\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Deep Neural network works better with numerical dataset. Each element is going to be replaced by a number.\n",
    "Input : matrix X and vector y non usable by a Deep Neural network.\n",
    "Output : X_train, y_train, X_test, y_test\n",
    "\"\"\"\n",
    "def dataset_for_NN(X, y, data, split_ratio):\n",
    "\n",
    "    unique_data = list(sorted(set(from_ndarrays_to_list(data)))) \n",
    "    dict_vocabulary = dict((element, nb) for nb, element in enumerate(unique_data)) # from element to integer\n",
    "    size_vocab = len(unique_data)\n",
    "\n",
    "    X_dataset = list()\n",
    "    y_dataset = list()\n",
    "    \n",
    "    for i in range(len(X)):\n",
    "        temp_X = []\n",
    "        for element in X[i]:\n",
    "            temp_X.append(dict_vocabulary[element])\n",
    "        X_dataset.append(temp_X)\n",
    "        y_dataset.append(dict_vocabulary[y[i]])\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(np.array(X_dataset), np.array(y_dataset),\n",
    "                                                        test_size=split_ratio, random_state=0)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = reshape(X_train, X_test, y_train, y_test, size_vocab)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, dict_vocabulary, size_vocab\n",
    "\n",
    "split_ratio = 0.2\n",
    "X_train, X_test, y_train, y_test, dict_vocabulary, size_vocab = dataset_for_NN(X, y, data_filtered, split_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure of the Models tested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Activation\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import BatchNormalization as BatchNorm\n",
    "from keras.layers import Bidirectional, Flatten\n",
    "from keras_self_attention import SeqSelfAttention\n",
    "# pip install keras-self-attention\n",
    "\n",
    "def lstm_model_1(window_size, dropout_rate, size_vocab):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(512, input_shape=(window_size, 1), recurrent_dropout=0.3, return_sequences=True))\n",
    "    model.add(LSTM(512, return_sequences=True, recurrent_dropout=0.3,))\n",
    "    model.add(LSTM(512))\n",
    "    model.add(BatchNorm())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNorm())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(size_vocab))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "\n",
    "    return model\n",
    "\n",
    "def lstm_model_2(window_size, dropout_rate, size_vocab):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(512, input_shape=(window_size, 1), return_sequences=True))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(LSTM(512, return_sequences=True))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(LSTM(512))\n",
    "    model.add(Dense(256))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(size_vocab))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "    \n",
    "    return model\n",
    "\n",
    "def lstm_attention_model(window_size, dropout_rate, size_vocab):\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(512,  input_shape=(window_size, 1),return_sequences=True)))\n",
    "    model.add(SeqSelfAttention(attention_activation='sigmoid'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(Bidirectional(LSTM(512,return_sequences=True)))\n",
    "    model.add(SeqSelfAttention(attention_activation='sigmoid'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(Bidirectional(LSTM(512,return_sequences=True)))\n",
    "    model.add(SeqSelfAttention(attention_activation='sigmoid'))\n",
    "    model.add(Dense(256))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(Flatten()) #Supposedly needed to fix stuff before dense layer\n",
    "    model.add(Dense(size_vocab))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "\n",
    "    return model\n",
    "\n",
    "def fit_model(model, X_train, y_train, batch_size, epochs, name, callbacks=False):\n",
    "    if callbacks is False:\n",
    "        model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1)\n",
    "    else:\n",
    "        filepath = \"weights-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\"    \n",
    "        checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=0, save_best_only=True, mode='min')    \n",
    "        callbacks_list = [checkpoint]\n",
    "        model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,\n",
    "                callbacks=callbacks_list, verbose=1)\n",
    "    \n",
    "    \n",
    "    # Save final model on disk\n",
    "    name_model = name+\".h5\"\n",
    "    lstm.save(name_model)\n",
    "    print(name_model + \" model saved on disk\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_1 = lstm_model_1(window_size, dropout_rate=0.3, size_vocab=size_vocab)\n",
    "#lstm_small = fit_model(lstm_1, X_train, y_train, batch_size=50, epochs=1, name=\"model_1\", callbacks=False)\n",
    "\n",
    "lstm_2 = lstm_model_2(window_size, dropout_rate=0.3, size_vocab=size_vocab)\n",
    "#lstm_2 = fit_model(lstm_2, X_train, y_train, batch_size=200, epochs=1, name=\"model_2\", callbacks=False)\n",
    "\n",
    "lstm_2 = lstm_attention_model(window_size, dropout_rate=0.3, size_vocab=size_vocab)\n",
    "#lstm_2 = fit_model(lstm_2, X_train, y_train, batch_size=200, epochs=1, name=\"model_2\", callbacks=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If a model needs to be loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "file_model = '/home/cj/Bureau/Master2/Q2/deep_learning/project/models/model_final_lstm_dunjon_small.h5'\n",
    "lstm = load_model(file_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If you have weights of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_weigts = \"/home/cj/Bureau/Master2/Q2/deep_learning/project/weights_sigur.hdf5\"  \n",
    "lstm.load_weights(file_weigts)\n",
    "lstm.compile(loss='categorical_crossentropy', optimizer='rmsprop')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_music(model, nb_steps, dict_vocabulary, input_sequence, size_vocab):\n",
    "    \n",
    "    prediction_output = []\n",
    "    for note in range(nb_steps):\n",
    "        prediction_input = np.reshape(input_sequence, (1, len(input_sequence), 1))\n",
    "        prediction_input = prediction_input/float(size_vocab) # normalization\n",
    "        pred = model.predict(prediction_input, verbose=0)\n",
    "        indice = np.argmax(pred) # takes the biggest probability\n",
    "        note_generated = dict_vocabulary[indice]\n",
    "        prediction_output.append(note_generated)\n",
    "        # The note generated is put at the end of the input sequence\n",
    "        input_sequence = np.append(input_sequence, indice)\n",
    "        # The first note is removed from the input sequence\n",
    "        input_sequence = input_sequence[1:len(input_sequence)]\n",
    "\n",
    "    return prediction_output\n",
    "\n",
    "unique_data = list(sorted(set(from_ndarrays_to_list(data_filtered)))) \n",
    "from_ind_to_element = dict((nb, element) for nb, element in enumerate(unique_data)) # from element to integer\n",
    "\n",
    "ind = np.random.randint(0, len(X_test)-1)\n",
    "input_sequence = X_test[ind]\n",
    "nb_steps_gen = 100\n",
    "\n",
    "music_generated = generate_music(lstm_2, nb_steps_gen, from_ind_to_element, input_sequence, size_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lol_melody.mid downloaded succesfully !\n"
     ]
    }
   ],
   "source": [
    "def from_notes_to_MIDI(music_generated, name, offset):\n",
    "    offset = 0\n",
    "    output_notes = []\n",
    "\n",
    "    # create note and chord objects based on the values generated by the model\n",
    "    for pattern in music_generated:\n",
    "        \n",
    "        # pattern is a chord\n",
    "        if ('.' in pattern) or pattern.isdigit():\n",
    "            notes_in_chord = pattern.split('.')\n",
    "            notes = []\n",
    "            for current_note in notes_in_chord:\n",
    "                \n",
    "                cn=int(current_note)\n",
    "                new_note = note.Note(cn)\n",
    "                new_note.storedInstrument = instrument.Piano()\n",
    "                notes.append(new_note)\n",
    "                \n",
    "            new_chord = chord.Chord(notes)\n",
    "            new_chord.offset = offset\n",
    "            output_notes.append(new_chord)\n",
    "            \n",
    "        elif('rest' in pattern):\n",
    "            new_rest = note.Rest(pattern)\n",
    "            new_rest.offset = offset\n",
    "            new_rest.storedInstrument = instrument.Piano() #???\n",
    "            output_notes.append(new_rest)\n",
    "            \n",
    "        # pattern is a note\n",
    "        else:\n",
    "            new_note = note.Note(pattern)\n",
    "            new_note.offset = offset\n",
    "            new_note.storedInstrument = instrument.Piano()\n",
    "            output_notes.append(new_note)\n",
    "\n",
    "        # increase offset each iteration so that notes do not stack\n",
    "        offset += 0.5\n",
    "    \n",
    "    midi_stream = stream.Stream(output_notes)\n",
    "    name_song = name+'.mid'\n",
    "    midi_stream.write('midi', fp=name_song)\n",
    "    print(name_song+\" downloaded succesfully !\")\n",
    "\n",
    "name_song = 'lol_melody'\n",
    "offset = 0.5\n",
    "from_notes_to_MIDI(music_generated, name_song, offset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper-parameters to optimize\n",
    "- Frequency threshold (done with data exploration)\n",
    "- time-step (window size)\n",
    "- dropout_rate\n",
    "- architecture (more complicated)\n",
    "- Number of batch\n",
    "- Number of epochs (PAY attention to the learning rate!)\n",
    "- size of the layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Todo\n",
    "- Work on hyper parameters\n",
    "- Add rythm and pause to the feature extraction\n",
    "- change function from element_to_midi accordingly\n",
    "- structure of the report\n",
    "- upoad library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('rstudio': conda)",
   "language": "python",
   "name": "python37464bitrstudioconda85139be567af4fb89143852fd1a4ee46"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
