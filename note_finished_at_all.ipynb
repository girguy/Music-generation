{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from music21 import *\n",
    "import glob\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras as keras\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import random\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Activation\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import BatchNormalization as BatchNorm\n",
    "from keras.layers import Bidirectional, Flatten\n",
    "from keras_self_attention import SeqSelfAttention\n",
    "# pip install keras-self-attention\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "This function extract the features from the MIDI files.\n",
    "\n",
    "Input : Directory containing the midi files\n",
    "outputs : numpy ndarray containing numpy arrays of the concatenated elements of the MIDI files.\n",
    "          Elements are feature extracted from the MIDI files.\n",
    "\"\"\"\n",
    "def read_midi_dataset(file): \n",
    "    notes = list()\n",
    "    for midi in glob.glob(file):\n",
    "        notes_to_parse = None\n",
    "        mu = converter.parse(midi)\n",
    "        s2 = instrument.partitionByInstrument(mu)\n",
    "        # parts[0] means we only takes into account piano\n",
    "        notes_to_parse = s2.parts[0].recurse() \n",
    "        notes_song = list()\n",
    "        for element in notes_to_parse:\n",
    "            \n",
    "            if isinstance(element, note.Note): # isinstance check if element is a note\n",
    "                notes_song.append(str(element.pitch))\n",
    "\n",
    "            elif isinstance(element, chord.Chord): # check if it is a chord\n",
    "                notes_song.append('.'.join(str(n) for n in element.normalOrder))   \n",
    "            \n",
    "            elif isinstance(element, note.Rest):\n",
    "                notes.append(str(element.name)  + \" \" + str(element.quarterLength))\n",
    "            \n",
    "        notes.append(notes_song)\n",
    "    \n",
    "    notes = np.array(notes)\n",
    "\n",
    "    return notes\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "This function transforms a numpy ndarray containaing arrays of elements of MIDI files into one list of\n",
    "these elements. Example : [[a,b][c,d]] => [a,b,c,d]\n",
    "\"\"\"\n",
    "def from_ndarrays_to_list(data):\n",
    "    return [element for elements_ in data for element in elements_] \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "This function shows an histogram of the notes and prints the total number of notes as well as the number\n",
    "of unique notes.\n",
    "\n",
    "Input : numpy ndarray containing numpy arrays of the concatenated elements of the\n",
    "        MIDI files.\n",
    "Output : No output. \n",
    "\"\"\"\n",
    "def data_exploration(data, printt=False, show=False):\n",
    "    elements_list = from_ndarrays_to_list(data)\n",
    "    unique_elements = list(set(elements_list))\n",
    "    frequence_of_elements = dict(Counter(elements_list))\n",
    "    \n",
    "    if printt is True:\n",
    "        print(\"The number of notes in the dataset is {}.\".format(len(elements_list)))\n",
    "        print(\"The number of different notes in the dataset is {}.\".format(len(unique_elements)))\n",
    "     \n",
    "    if show is True : # histogram of the notes\n",
    "        plt.bar(list(frequence_of_elements.keys()), frequence_of_elements.values(), color='g')\n",
    "        plt.show()\n",
    "\n",
    "        \n",
    "\"\"\"\n",
    "This function deletes from the dataset elements that do not appear more than a particular frequency.\n",
    "It is a filter.\n",
    "Input : numpy ndarray containing numpy arrays of the concatenated elements of the MIDI files.\n",
    "Output : List of list. Each list is a concatenation of all the elements of a MIDI file.\n",
    "\"\"\"\n",
    "def select_notes(data, frequency, printt=False):\n",
    "    elements_list = from_ndarrays_to_list(data)\n",
    "    frequence_of_notes = dict(Counter(elements_list))\n",
    "    # unique_elements is the sorted set of unique elements of the set of MIDI files. The elements selected depends\n",
    "    # on a particular frequency. Therefore, it is the total vacabulary of the dataset.\n",
    "    unique_elements = sorted([elements_list for elements_list,\n",
    "                              count in frequence_of_notes.items() if count>=frequency])\n",
    "\n",
    "    if printt is True :\n",
    "        print(\"The number of different notes that appear at least {} time is {}.\".format(frequency,\n",
    "                                                                                     len(unique_elements)))\n",
    "    new_data = list()\n",
    "    for elements_ in data:\n",
    "        temp = list()\n",
    "        for element in elements_:\n",
    "            if element in unique_elements:\n",
    "                temp.append(element)\n",
    "        new_data.append(temp)\n",
    "        \n",
    "    return new_data\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "This function creates the X and y matrices needed by the model.\n",
    "We use a sliding window mechanism in order to create this dataset.\n",
    "[a,b,c,d,e,f,g] becomes x1=[a,b,c], y1=[d] then x2=[b,c,d], y2=[e] etc.\n",
    "\n",
    "Input : List of list. Each list is a concatenation of all the elements of a MIDI file.\n",
    "Output : matrix X and vector y.\n",
    "\"\"\"\n",
    "def create_dataset(data, window): #time_step = window\n",
    "    x = list()\n",
    "    y = list()\n",
    "    for elements_ in data:\n",
    "        for i in range(len(elements_)-window):\n",
    "            x.append(elements_[i:i + window])\n",
    "            y.append(elements_[i + window])\n",
    "    \n",
    "    return np.array(x), np.array(y)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "This function makes the different matrices usable by an LSTM unit.\n",
    "input : For X matrices : [nb_samples, window_size]\n",
    "        For y matrices : [nb_samples, ]\n",
    "output : For X matrices : [nb_samples, window_size, 1] # 1 because there is only one feature (element)\n",
    "         For y matrices : [nb_samples, vocabulary_size] # One-hot encoding\n",
    "\"\"\"\n",
    "def reshape(X_train, X_test, y_train, y_test, size_vocab):\n",
    "    y_train = keras.utils.np_utils.to_categorical(y_train, num_classes = size_vocab)\n",
    "    y_test = keras.utils.np_utils.to_categorical(y_test, num_classes = size_vocab)\n",
    "    X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))/float(size_vocab) # Normalization\n",
    "    X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))/float(size_vocab) # Normalization\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Deep Neural network works better with numerical dataset. Each element is going to be replaced by a number.\n",
    "Input : matrix X and vector y non usable by a Deep Neural network.\n",
    "Output : X_train, y_train, X_test, y_test\n",
    "\"\"\"\n",
    "def dataset_for_NN(X, y, data, split_ratio):\n",
    "\n",
    "    unique_data = list(sorted(set(from_ndarrays_to_list(data)))) \n",
    "    dict_vocabulary = dict((element, nb) for nb, element in enumerate(unique_data)) # from element to integer\n",
    "    size_vocab = len(unique_data)\n",
    "\n",
    "    X_dataset = list() \n",
    "    y_dataset = list()\n",
    "    \n",
    "    for i in range(len(X)):\n",
    "        temp_X = []\n",
    "        for element in X[i]:\n",
    "            temp_X.append(dict_vocabulary[element])\n",
    "        X_dataset.append(temp_X)\n",
    "        y_dataset.append(dict_vocabulary[y[i]])\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(np.array(X_dataset), np.array(y_dataset),\n",
    "                                                        test_size=split_ratio, random_state=0)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = reshape(X_train, X_test, y_train, y_test, size_vocab)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, dict_vocabulary, size_vocab\n",
    "\n",
    "\n",
    "\n",
    "def lstm_model_1(window_size, dropout_rate, size_vocab, size_lstm):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(size_lstm, input_shape=(window_size, 1), return_sequences=True)) # 512\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(LSTM(size_lstm, return_sequences=True)) # 512\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(LSTM(size_lstm)) # 512\n",
    "    model.add(Dense(256))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(size_vocab))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def lstm_model_2(window_size, dropout_rate, size_vocab, size_lstm):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(size_lstm, input_shape=(window_size, 1), recurrent_dropout=0.3, return_sequences=True)) # 512\n",
    "    model.add(LSTM(size_lstm, return_sequences=True, recurrent_dropout=0.3)) # 512\n",
    "    model.add(LSTM(size_lstm)) # 512\n",
    "    model.add(BatchNorm())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNorm())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(size_vocab))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "def lstm_attention_model_big(window_size, dropout_rate, size_vocab, size_lstm):\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(size_lstm, input_shape=(window_size, 1),return_sequences=True))) # 512\n",
    "    model.add(SeqSelfAttention(attention_activation='sigmoid'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(Bidirectional(LSTM(size_lstm, return_sequences=True))) # 512\n",
    "    model.add(SeqSelfAttention(attention_activation='sigmoid'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(Bidirectional(LSTM(size_lstm, return_sequences=True))) # 512\n",
    "    model.add(SeqSelfAttention(attention_activation='sigmoid'))\n",
    "    model.add(Dense(256))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(Flatten()) #Supposedly needed to fix stuff before dense layer\n",
    "    model.add(Dense(size_vocab))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "def lstm_attention_model(window_size, dropout_rate, size_vocab, size_lstm):\n",
    "    \"\"\" create the structure of the neural network \"\"\"\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Bidirectional(LSTM(size_lstm, input_shape=(window_size, 1),return_sequences=True))) # 512\n",
    "    model.add(SeqSelfAttention(attention_activation='sigmoid'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(LSTM(size_lstm,return_sequences=True))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Flatten()) #Supposedly needed to fix stuff before dense layer\n",
    "    model.add(Dense(size_vocab))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "def save_on_disk(model, history, name):\n",
    "    name_model = name+\".h5\"\n",
    "    model.save(name_model)\n",
    "    print(name_model + \" model saved on disk\")\n",
    "    \n",
    "    history_ = pd.DataFrame.from_dict(history.history, orient='index')\n",
    "    name_history = name+\"_history.csv\"\n",
    "    print(name_history + \" history saved on disk\")\n",
    "    history_.to_csv(name_history)\n",
    "\n",
    "\n",
    "# An history object is the output of the fit(), it keeps tracks of the value of\n",
    "# [loss, val_loss, accuracy, val_accuray] for each epoch during the training of the model.\n",
    "# Very important to plot the learning curve for the training (loss) and testing set (val_loss).\n",
    "def fit_model(model, X_train, y_train, X_test, y_test, batch_size, epochs, name, callbacks=False):\n",
    "    if callbacks is False:\n",
    "        history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs,\n",
    "                  batch_size=batch_size, verbose=1)\n",
    "    else:\n",
    "        filepath = \"weights-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\"    \n",
    "        checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=0, save_best_only=True, mode='min')    \n",
    "        callbacks_list = [checkpoint]\n",
    "        history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs,\n",
    "                  batch_size=batch_size, callbacks=callbacks_list, verbose=1)\n",
    "    \n",
    "    # Save results on disk\n",
    "    save_on_disk(model, history, name)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def get_model(which, window_size, dropout_rate, size_vocab, X_train, y_train, X_test, y_test,\n",
    "             size_lstm, batch_size, epochs, name_param, callbacks):\n",
    "    if which == 1:\n",
    "        name = 'lstm_model_1'+name_param\n",
    "        model = lstm_model_1(window_size, dropout_rate, size_vocab, size_lstm)\n",
    "        #model = fit_model(model, X_train, y_train, X_test, y_test, batch_size, epochs, name, callbacks)\n",
    "\n",
    "    elif which == 2:\n",
    "        name = 'lstm_model_2'+name_param\n",
    "        model = lstm_model_2(window_size, dropout_rate, size_vocab, size_lstm)\n",
    "        #model = fit_model(model, X_train, y_train, X_test, y_test, batch_size, epochs, name, callbacks)\n",
    "\n",
    "    elif which == 3:\n",
    "        name = 'lstm_att_model'+name_param\n",
    "        model = lstm_attention_model(window_size, dropout_rate, size_vocab, size_lstm)\n",
    "        #model = fit_model(model, X_train, y_train, X_test, y_test, batch_size, epochs, name, callbacks)\n",
    "\n",
    "    else:\n",
    "        return print(\"No corresponding model\")\n",
    "\n",
    "    return model\n",
    "\n",
    "def get_dataset(file, frequency, window_size):\n",
    "    \n",
    "    data_elements = read_midi_dataset(file)\n",
    "    data_filtered = select_notes(data_elements, frequency=frequency)\n",
    "    \n",
    "    unique_data = list(sorted(set(from_ndarrays_to_list(data_filtered))))\n",
    "    from_ind_to_element = dict((nb, element) for nb, element in enumerate(unique_data)) # from element to integer\n",
    "    \n",
    "    X, y = create_dataset(data_filtered, window_size)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test, dict_vocabulary, size_vocab = dataset_for_NN(X, y, data_filtered,\n",
    "                                                                                   split_ratio=0.2)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, dict_vocabulary, size_vocab, from_ind_to_element\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # PARAMETERS\n",
    "    file = \"/home/cj/Bureau/Master2/Q2/deep_learning/project/tf_dataset/*.mid\"\n",
    "    \n",
    "    frequency = 0\n",
    "    window_size = 16 # [32, 64, 100] => last to test\n",
    "    dropout_rate = 0.3 # [0, 0.2, 0.4, 0.8] => second to test\n",
    "    batch_size = 5 # [128, 256, 512, 1024] => third to test\n",
    "    epochs = 1\n",
    "    which = 1 \n",
    "    \n",
    "    size_lstm = 32\n",
    "    name_param = '_size_512' # ['_size_64', '_size_128', '_size_256', '_size_512'] \n",
    "    \n",
    "    X_train, X_test, y_train, y_test, dict_vocabulary, size_vocab, from_ind_to_element = get_dataset(file, frequency, window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_7 (LSTM)                (None, 16, 32)            4352      \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 16, 32)            0         \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 16, 32)            8320      \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 16, 32)            0         \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 32)                8320      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               8448      \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 176)               45232     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 176)               0         \n",
      "=================================================================\n",
      "Total params: 74,672\n",
      "Trainable params: 74,672\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_model(which, window_size, dropout_rate, size_vocab, X_train, y_train, X_test, y_test,\n",
    "             size_lstm, batch_size, epochs, name_param, callbacks=False)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6003 samples, validate on 1501 samples\n",
      "Epoch 1/1\n",
      "6003/6003 [==============================] - 48s 8ms/step - loss: 4.3456 - accuracy: 0.0441 - val_loss: 4.3065 - val_accuracy: 0.0513\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs,\n",
    "                  batch_size=batch_size, callbacks=False, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_25 (LSTM)               (None, 16, 32)            4352      \n",
      "_________________________________________________________________\n",
      "lstm_26 (LSTM)               (None, 16, 32)            8320      \n",
      "_________________________________________________________________\n",
      "lstm_27 (LSTM)               (None, 16, 32)            8320      \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 16, 256)           8448      \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 16, 256)           0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 16, 176)           45232     \n",
      "=================================================================\n",
      "Total params: 74,672\n",
      "Trainable params: 74,672\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "def build_model(vocab_size, embedding_dim, size_lstm, window_size, dropout):\n",
    "    \n",
    "    model = tf.keras.Sequential([\n",
    "        \n",
    "        tf.keras.layers.LSTM(size_lstm,\n",
    "                             input_shape=(window_size, 1),\n",
    "                             dropout=dropout,\n",
    "                             return_sequences=True),\n",
    "        tf.keras.layers.LSTM(size_lstm,\n",
    "                             dropout=dropout,\n",
    "                             return_sequences=True),\n",
    "        tf.keras.layers.LSTM(size_lstm,\n",
    "                             return_sequences=True),\n",
    "        \n",
    "        tf.keras.layers.Dense(256),\n",
    "        \n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(vocab_size, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 1000\n",
    "#dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "#dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "\n",
    "vocab_size = size_vocab\n",
    "embedding_dim = 256\n",
    "window_size = 16\n",
    "size_lstm = 32\n",
    "dropout = 0.3\n",
    "\n",
    "model1 = build_model(\n",
    "    vocab_size = size_vocab,\n",
    "    embedding_dim=embedding_dim,\n",
    "    size_lstm=size_lstm,\n",
    "    window_size=window_size,\n",
    "    dropout=dropout)\n",
    "\n",
    "def loss(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "\n",
    "model1.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "print(model1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6003 samples, validate on 1501 samples\n",
      "Epoch 1/1\n",
      "6003/6003 [==============================] - 52s 9ms/step - loss: 4.3461 - accuracy: 0.0436 - val_loss: 4.3732 - val_accuracy: 0.0380\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs,\n",
    "                     batch_size=batch_size, callbacks=False, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "A target array with shape (6003, 176) was passed for an output of shape (None, 16, 176) while using as loss `categorical_crossentropy`. This loss expects targets to have the same shape as the output.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-e88a9c81762b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m history = model1.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs,\n\u001b[0;32m----> 2\u001b[0;31m                      batch_size=batch_size, callbacks=False, verbose=1)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/rstudio/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/rstudio/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    233\u001b[0m           \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m           use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data_adapter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rstudio/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_training_inputs\u001b[0;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, steps_per_epoch, validation_split, validation_data, validation_steps, shuffle, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    594\u001b[0m     \u001b[0mval_adapter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rstudio/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[0;34m(model, mode, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    644\u001b[0m     \u001b[0mstandardize_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m     x, y, sample_weights = standardize(\n\u001b[0;32m--> 646\u001b[0;31m         x, y, sample_weight=sample_weights)\n\u001b[0m\u001b[1;32m    647\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0madapter_cls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mdata_adapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mListsOfScalarsDataAdapter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[0mstandardize_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstandardize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rstudio/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2381\u001b[0m         \u001b[0mis_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2382\u001b[0m         \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2383\u001b[0;31m         batch_size=batch_size)\n\u001b[0m\u001b[1;32m   2384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2385\u001b[0m   def _standardize_tensors(self, x, y, sample_weight, run_eagerly, dict_inputs,\n",
      "\u001b[0;32m~/anaconda3/envs/rstudio/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_tensors\u001b[0;34m(self, x, y, sample_weight, run_eagerly, dict_inputs, is_dataset, class_weight, batch_size)\u001b[0m\n\u001b[1;32m   2487\u001b[0m           \u001b[0;31m# Additional checks to avoid users mistakenly using improper loss fns.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2488\u001b[0m           training_utils.check_loss_and_target_compatibility(\n\u001b[0;32m-> 2489\u001b[0;31m               y, self._feed_loss_fns, feed_output_shapes)\n\u001b[0m\u001b[1;32m   2490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2491\u001b[0m       sample_weights, _, _ = training_utils.handle_partial_sample_weights(\n",
      "\u001b[0;32m~/anaconda3/envs/rstudio/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mcheck_loss_and_target_compatibility\u001b[0;34m(targets, loss_fns, output_shapes)\u001b[0m\n\u001b[1;32m    808\u001b[0m           raise ValueError('A target array with shape ' + str(y.shape) +\n\u001b[1;32m    809\u001b[0m                            \u001b[0;34m' was passed for an output of shape '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m                            \u001b[0;34m' while using as loss `'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'`. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m                            \u001b[0;34m'This loss expects targets to have the same shape '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m                            'as the output.')\n",
      "\u001b[0;31mValueError\u001b[0m: A target array with shape (6003, 176) was passed for an output of shape (None, 16, 176) while using as loss `categorical_crossentropy`. This loss expects targets to have the same shape as the output."
     ]
    }
   ],
   "source": [
    "history = model1.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs,\n",
    "                     batch_size=batch_size, callbacks=False, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00569914, 0.00553793, 0.00569489, 0.00545355, 0.00577031,\n",
       "        0.00550953, 0.00581398, 0.00573637, 0.00562528, 0.00571222,\n",
       "        0.00579471, 0.00567932, 0.00583001, 0.00564577, 0.00579699,\n",
       "        0.00568858, 0.005629  , 0.00569668, 0.00573159, 0.00556602,\n",
       "        0.00564992, 0.00569542, 0.00560821, 0.00581642, 0.00576097,\n",
       "        0.00581209, 0.00568126, 0.00576079, 0.00582431, 0.00560498,\n",
       "        0.00562446, 0.00563818, 0.0055183 , 0.00580436, 0.00565491,\n",
       "        0.00557531, 0.00562761, 0.00565178, 0.00602327, 0.00564603,\n",
       "        0.0057475 , 0.00575072, 0.00561352, 0.00580092, 0.00551467,\n",
       "        0.00567524, 0.00556749, 0.00587532, 0.00568032, 0.00545016,\n",
       "        0.00564928, 0.00582458, 0.0055914 , 0.00582056, 0.00569557,\n",
       "        0.00543937, 0.00572302, 0.00558731, 0.00574581, 0.00564616,\n",
       "        0.00567745, 0.00577958, 0.00587261, 0.00552825, 0.00565038,\n",
       "        0.00582557, 0.00587031, 0.00561917, 0.00560633, 0.00569939,\n",
       "        0.00557657, 0.0056322 , 0.0056684 , 0.00576064, 0.00569791,\n",
       "        0.0058124 , 0.00575441, 0.00562857, 0.00546817, 0.00565191,\n",
       "        0.00572933, 0.00556268, 0.00566112, 0.00556582, 0.00566121,\n",
       "        0.00573676, 0.00555834, 0.00552706, 0.00578522, 0.00564712,\n",
       "        0.00568057, 0.00569301, 0.00572675, 0.0054375 , 0.00560966,\n",
       "        0.00568113, 0.00559814, 0.00568174, 0.00568979, 0.00579786,\n",
       "        0.00556905, 0.00564734, 0.00582582, 0.00572532, 0.00564581,\n",
       "        0.00568246, 0.005624  , 0.00570009, 0.0056442 , 0.00575928,\n",
       "        0.00562996, 0.00562917, 0.00568866, 0.00572537, 0.00577632,\n",
       "        0.00561804, 0.00563717, 0.00569532, 0.0056923 , 0.00560521,\n",
       "        0.00577946, 0.00583304, 0.0056561 , 0.00563012, 0.00562781,\n",
       "        0.00593604, 0.00552972, 0.00570934, 0.00576886, 0.00565657,\n",
       "        0.00568281, 0.00581063, 0.00560739, 0.00578092, 0.00572074,\n",
       "        0.00578954, 0.00573954, 0.00557817, 0.00569108, 0.00589028,\n",
       "        0.00574959, 0.00554797, 0.00574289, 0.00576856, 0.00546553,\n",
       "        0.0058203 , 0.00580544, 0.00563693, 0.00573497, 0.00571118,\n",
       "        0.0056649 , 0.00554432, 0.00563517, 0.00561279, 0.0058984 ,\n",
       "        0.00561246, 0.00571354, 0.00564046, 0.00543306, 0.00571929,\n",
       "        0.00569996, 0.00574842, 0.00571692, 0.00558843, 0.00562325,\n",
       "        0.00566862, 0.00550134, 0.00573326, 0.00566343, 0.00568802,\n",
       "        0.00562303, 0.00580197, 0.00565451, 0.00559425, 0.00574879,\n",
       "        0.00574862]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = np.reshape(X_test[0], (1, len(X_test[0]), 1))\n",
    "example_batch_predictions = model.predict(d, verbose=0)\n",
    "example_batch_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00568016, 0.00568141, 0.00568334, ..., 0.00568337, 0.00568222,\n",
       "        0.00568207],\n",
       "       [0.00567712, 0.00568028, 0.00568638, ..., 0.00568639, 0.00568258,\n",
       "        0.00568214],\n",
       "       [0.00567261, 0.0056781 , 0.00569124, ..., 0.00569086, 0.00568261,\n",
       "        0.00568153],\n",
       "       ...,\n",
       "       [0.00559787, 0.00560453, 0.00576161, ..., 0.00573363, 0.00565939,\n",
       "        0.00562391],\n",
       "       [0.00559193, 0.00559726, 0.00576556, ..., 0.00573487, 0.00565813,\n",
       "        0.00561812],\n",
       "       [0.0055864 , 0.00559028, 0.00576913, ..., 0.00573578, 0.00565713,\n",
       "        0.00561258]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = np.reshape(X_test[0], (1, len(X_test[0]), 1))\n",
    "example_batch_predictions = model1.predict(d, verbose=0)[0]\n",
    "example_batch_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 16, 176)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_batch_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'i' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-2ad68b332e8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m model = get_model(which, window_size, dropout_rate, size_vocab, X_train, y_train, X_test, y_test,\n\u001b[0;32m----> 2\u001b[0;31m                      size_lstm[i], batch_size, epochs, name_param[i], callbacks=False)\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'i' is not defined"
     ]
    }
   ],
   "source": [
    "model = get_model(which, window_size, dropout_rate, size_vocab, X_train, y_train, X_test, y_test,\n",
    "                     size_lstm[i], batch_size, epochs, name_param[i], callbacks=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genererate music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "def generate_music(model, nb_steps, dict_vocabulary, input_sequence, size_vocab):\n",
    "    prediction_output = []\n",
    "    for note in range(nb_steps):\n",
    "        prediction_input = np.reshape(input_sequence, (1, len(input_sequence), 1))\n",
    "        prediction_input = prediction_input/float(size_vocab) # normalization\n",
    "        pred = model.predict(prediction_input, verbose=0)\n",
    "        indice = np.argmax(pred) # takes the biggest probability\n",
    "        note_generated = dict_vocabulary[indice]\n",
    "        prediction_output.append(note_generated)\n",
    "        # The note generated is put at the end of the input sequence\n",
    "        input_sequence = np.append(input_sequence, indice)\n",
    "        # The first note is removed from the input sequence\n",
    "        input_sequence = input_sequence[1:len(input_sequence)]\n",
    "\n",
    "    return prediction_output\n",
    "\n",
    "def from_notes_to_MIDI(music_generated, name, tempo):\n",
    "    \n",
    "    offset = 0\n",
    "    output_notes = []\n",
    "    # create note and chord objects based on the values generated by the model\n",
    "    for pattern in music_generated:\n",
    "        \n",
    "        # pattern is a chord\n",
    "        if ('.' in pattern) or pattern.isdigit():\n",
    "            notes_in_chord = pattern.split('.')\n",
    "            notes = []\n",
    "            for current_note in notes_in_chord:\n",
    "                \n",
    "                cn=int(current_note)\n",
    "                new_note = note.Note(cn)\n",
    "                new_note.storedInstrument = instrument.Piano()\n",
    "                notes.append(new_note)\n",
    "                \n",
    "            new_chord = chord.Chord(notes)\n",
    "            new_chord.offset = offset\n",
    "            output_notes.append(new_chord)\n",
    "            \n",
    "        elif('rest' in pattern):\n",
    "            new_rest = note.Rest(pattern)\n",
    "            new_rest.offset = offset\n",
    "            new_rest.storedInstrument = instrument.Piano() #???\n",
    "            output_notes.append(new_rest)\n",
    "            \n",
    "        # pattern is a note\n",
    "        else:\n",
    "            new_note = note.Note(pattern)\n",
    "            new_note.offset = offset\n",
    "            new_note.storedInstrument = instrument.Piano()\n",
    "            output_notes.append(new_note)\n",
    "\n",
    "        # increase offset each iteration so that notes do not stack\n",
    "        offset += tempo\n",
    "    \n",
    "    midi_stream = stream.Stream(output_notes)\n",
    "    name_song = name+'.mid'\n",
    "    midi_stream.write('midi', fp=name_song)\n",
    "    print(name_song+\" downloaded succesfully !\")\n",
    "\n",
    "def get_music(file, model, nb_steps, from_ind_to_element, input_sequence, size_vocab, name_song):\n",
    "  \n",
    "    if file[-2:] == 'f5':\n",
    "        print(model)\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "        print('Model loaded and compiled !')\n",
    "    elif file[-2:] == 'h5':\n",
    "        model = load_model(file)\n",
    "        print('Model loaded')\n",
    "    else:\n",
    "        print(file[-2:])\n",
    "        return print('Type of file not supported.')\n",
    "    \n",
    "    music_generated = generate_music(model, nb_steps, from_ind_to_element, input_sequence, size_vocab)\n",
    "    tempo = 0.5\n",
    "    from_notes_to_MIDI(music_generated, name_song, tempo)\n",
    "    return music_generated\n",
    "\n",
    "        \n",
    "if __name__ == \"__main__\": \n",
    "    \n",
    "    window_size = 32; droupout_rate=0.3; size_lstm = 512;\n",
    "    model = get_model(which, window_size, dropout_rate, size_vocab, X_train, y_train, X_test, y_test,\n",
    "                      size_lstm, batch_size, epochs, '_model_2_allsongs', callbacks=False)\n",
    "\n",
    "    file = \"/home/cj/Téléchargements/model_2_window/model/lstm_model_2_window_16.h5\"\n",
    "    ind = np.random.randint(0, len(X_test)-1)\n",
    "    input_sequence = X_test[ind]\n",
    "    nb_steps = 200\n",
    "    name_song = 'model_2_pok_2'\n",
    "    music_generated = get_music(file, model, nb_steps, from_ind_to_element, input_sequence, size_vocab, name_song)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('rstudio': conda)",
   "language": "python",
   "name": "python37464bitrstudioconda85139be567af4fb89143852fd1a4ee46"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
