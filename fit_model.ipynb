{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from music21 import *\n",
    "import glob\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras as keras\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import random\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Activation\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import BatchNormalization as BatchNorm\n",
    "from keras.layers import Bidirectional, Flatten\n",
    "from keras_self_attention import SeqSelfAttention\n",
    "# pip install keras-self-attention\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "This function extract the features from the MIDI files.\n",
    "\n",
    "Input : Directory containing the midi files\n",
    "outputs : numpy ndarray containing numpy arrays of the concatenated elements of the MIDI files.\n",
    "          Elements are feature extracted from the MIDI files.\n",
    "\"\"\"\n",
    "def read_midi_dataset(file): \n",
    "    notes = list()\n",
    "    for midi in glob.glob(file):\n",
    "        notes_to_parse = None\n",
    "        mu = converter.parse(midi)\n",
    "        s2 = instrument.partitionByInstrument(mu)\n",
    "        # parts[0] means we only takes into account piano\n",
    "        notes_to_parse = s2.parts[0].recurse() \n",
    "        notes_song = list()\n",
    "        for element in notes_to_parse:\n",
    "            \n",
    "            if isinstance(element, note.Note): # isinstance check if element is a note\n",
    "                notes_song.append(str(element.pitch))\n",
    "\n",
    "            elif isinstance(element, chord.Chord): # check if it is a chord\n",
    "                notes_song.append('.'.join(str(n) for n in element.normalOrder))   \n",
    "            \n",
    "            elif isinstance(element, note.Rest):\n",
    "                notes.append(str(element.name)  + \" \" + str(element.quarterLength))\n",
    "            \n",
    "        notes.append(notes_song)\n",
    "    \n",
    "    notes = np.array(notes)\n",
    "\n",
    "    return notes\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "This function transforms a numpy ndarray containaing arrays of elements of MIDI files into one list of\n",
    "these elements. Example : [[a,b][c,d]] => [a,b,c,d]\n",
    "\"\"\"\n",
    "def from_ndarrays_to_list(data):\n",
    "    return [element for elements_ in data for element in elements_] \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "This function shows an histogram of the notes and prints the total number of notes as well as the number\n",
    "of unique notes.\n",
    "\n",
    "Input : numpy ndarray containing numpy arrays of the concatenated elements of the\n",
    "        MIDI files.\n",
    "Output : No output. \n",
    "\"\"\"\n",
    "def data_exploration(data, printt=False, show=False):\n",
    "    elements_list = from_ndarrays_to_list(data)\n",
    "    unique_elements = list(set(elements_list))\n",
    "    frequence_of_elements = dict(Counter(elements_list))\n",
    "    \n",
    "    if printt is True:\n",
    "        print(\"The number of notes in the dataset is {}.\".format(len(elements_list)))\n",
    "        print(\"The number of different notes in the dataset is {}.\".format(len(unique_elements)))\n",
    "     \n",
    "    if show is True : # histogram of the notes\n",
    "        plt.bar(list(frequence_of_elements.keys()), frequence_of_elements.values(), color='g')\n",
    "        plt.show()\n",
    "\n",
    "        \n",
    "\"\"\"\n",
    "This function deletes from the dataset elements that do not appear more than a particular frequency.\n",
    "It is a filter.\n",
    "Input : numpy ndarray containing numpy arrays of the concatenated elements of the MIDI files.\n",
    "Output : List of list. Each list is a concatenation of all the elements of a MIDI file.\n",
    "\"\"\"\n",
    "def select_notes(data, frequency, printt=False):\n",
    "    elements_list = from_ndarrays_to_list(data)\n",
    "    frequence_of_notes = dict(Counter(elements_list))\n",
    "    # unique_elements is the sorted set of unique elements of the set of MIDI files. The elements selected depends\n",
    "    # on a particular frequency. Therefore, it is the total vacabulary of the dataset.\n",
    "    unique_elements = sorted([elements_list for elements_list,\n",
    "                              count in frequence_of_notes.items() if count>=frequency])\n",
    "\n",
    "    if printt is True :\n",
    "        print(\"The number of different notes that appear at least {} time is {}.\".format(frequency,\n",
    "                                                                                     len(unique_elements)))\n",
    "    new_data = list()\n",
    "    for elements_ in data:\n",
    "        temp = list()\n",
    "        for element in elements_:\n",
    "            if element in unique_elements:\n",
    "                temp.append(element)\n",
    "        new_data.append(temp)\n",
    "        \n",
    "    return new_data\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "This function creates the X and y matrices needed by the model.\n",
    "We use a sliding window mechanism in order to create this dataset.\n",
    "[a,b,c,d,e,f,g] becomes x1=[a,b,c], y1=[d] then x2=[b,c,d], y2=[e] etc.\n",
    "\n",
    "Input : List of list. Each list is a concatenation of all the elements of a MIDI file.\n",
    "Output : matrix X and vector y.\n",
    "\"\"\"\n",
    "def create_dataset(data, window): #time_step = window\n",
    "    x = list()\n",
    "    y = list()\n",
    "    for elements_ in data:\n",
    "        for i in range(len(elements_)-window):\n",
    "            x.append(elements_[i:i + window])\n",
    "            y.append(elements_[i + window])\n",
    "    \n",
    "    return np.array(x), np.array(y)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "This function makes the different matrices usable by an LSTM unit.\n",
    "input : For X matrices : [nb_samples, window_size]\n",
    "        For y matrices : [nb_samples, ]\n",
    "output : For X matrices : [nb_samples, window_size, 1] # 1 because there is only one feature (element)\n",
    "         For y matrices : [nb_samples, vocabulary_size] # One-hot encoding\n",
    "\"\"\"\n",
    "def reshape(X_train, X_test, y_train, y_test, size_vocab):\n",
    "    y_train = keras.utils.np_utils.to_categorical(y_train, num_classes = size_vocab)\n",
    "    y_test = keras.utils.np_utils.to_categorical(y_test, num_classes = size_vocab)\n",
    "    X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))/float(size_vocab) # Normalization\n",
    "    X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))/float(size_vocab) # Normalization\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Deep Neural network works better with numerical dataset. Each element is going to be replaced by a number.\n",
    "Input : matrix X and vector y non usable by a Deep Neural network.\n",
    "Output : X_train, y_train, X_test, y_test\n",
    "\"\"\"\n",
    "def dataset_for_NN(X, y, data, split_ratio):\n",
    "\n",
    "    unique_data = list(sorted(set(from_ndarrays_to_list(data)))) \n",
    "    dict_vocabulary = dict((element, nb) for nb, element in enumerate(unique_data)) # from element to integer\n",
    "    size_vocab = len(unique_data)\n",
    "\n",
    "    X_dataset = list()\n",
    "    y_dataset = list()\n",
    "    \n",
    "    for i in range(len(X)):\n",
    "        temp_X = []\n",
    "        for element in X[i]:\n",
    "            temp_X.append(dict_vocabulary[element])\n",
    "        X_dataset.append(temp_X)\n",
    "        y_dataset.append(dict_vocabulary[y[i]])\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(np.array(X_dataset), np.array(y_dataset),\n",
    "                                                        test_size=split_ratio, random_state=0)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = reshape(X_train, X_test, y_train, y_test, size_vocab)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, dict_vocabulary, size_vocab\n",
    "\n",
    "\n",
    "\n",
    "def lstm_model_1(window_size, dropout_rate, size_vocab, size_lstm):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(size_lstm, input_shape=(window_size, 1), return_sequences=True)) # 512\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(LSTM(size_lstm, return_sequences=True)) # 512\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(LSTM(size_lstm)) # 512\n",
    "    model.add(Dense(256))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(size_vocab))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def lstm_model_2(window_size, dropout_rate, size_vocab, size_lstm):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(size_lstm, input_shape=(window_size, 1), recurrent_dropout=0.3, return_sequences=True)) # 512\n",
    "    model.add(LSTM(size_lstm, return_sequences=True, recurrent_dropout=0.3)) # 512\n",
    "    model.add(LSTM(size_lstm)) # 512\n",
    "    model.add(BatchNorm())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNorm())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(size_vocab))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "def lstm_attention_model_big(window_size, dropout_rate, size_vocab, size_lstm):\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(size_lstm, input_shape=(window_size, 1),return_sequences=True))) # 512\n",
    "    model.add(SeqSelfAttention(attention_activation='sigmoid'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(Bidirectional(LSTM(size_lstm, return_sequences=True))) # 512\n",
    "    model.add(SeqSelfAttention(attention_activation='sigmoid'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(Bidirectional(LSTM(size_lstm, return_sequences=True))) # 512\n",
    "    model.add(SeqSelfAttention(attention_activation='sigmoid'))\n",
    "    model.add(Dense(256))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(Flatten()) #Supposedly needed to fix stuff before dense layer\n",
    "    model.add(Dense(size_vocab))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "def lstm_attention_model(window_size, dropout_rate, size_vocab, size_lstm):\n",
    "    \"\"\" create the structure of the neural network \"\"\"\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Bidirectional(LSTM(size_lstm, input_shape=(window_size, 1),return_sequences=True))) # 512\n",
    "    model.add(SeqSelfAttention(attention_activation='sigmoid'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(LSTM(size_lstm,return_sequences=True))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Flatten()) #Supposedly needed to fix stuff before dense layer\n",
    "    model.add(Dense(size_vocab))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "def save_on_disk(model, history, name):\n",
    "    name_model = name+\".h5\"\n",
    "    model.save(name_model)\n",
    "    print(name_model + \" model saved on disk\")\n",
    "    \n",
    "    history_ = pd.DataFrame.from_dict(history.history, orient='index')\n",
    "    name_history = name+\"_history.csv\"\n",
    "    print(name_history + \" history saved on disk\")\n",
    "    history_.to_csv(name_history)\n",
    "\n",
    "\n",
    "# An history object is the output of the fit(), it keeps tracks of the value of\n",
    "# [loss, val_loss, accuracy, val_accuray] for each epoch during the training of the model.\n",
    "# Very important to plot the learning curve for the training (loss) and testing set (val_loss).\n",
    "def fit_model(model, X_train, y_train, X_test, y_test, batch_size, epochs, name, callbacks=False):\n",
    "    if callbacks is False:\n",
    "        history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs,\n",
    "                  batch_size=batch_size, verbose=1)\n",
    "    else:\n",
    "        filepath = \"weights-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\"    \n",
    "        checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=0, save_best_only=True, mode='min')    \n",
    "        callbacks_list = [checkpoint]\n",
    "        history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs,\n",
    "                  batch_size=batch_size, callbacks=callbacks_list, verbose=1)\n",
    "    \n",
    "    # Save results on disk\n",
    "    save_on_disk(model, history, name)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def get_model(which, window_size, dropout_rate, size_vocab, X_train, y_train, X_test, y_test,\n",
    "             size_lstm, batch_size, epochs, name_param, callbacks):\n",
    "    if which == 1:\n",
    "        name = 'lstm_model_1'+name_param\n",
    "        model = lstm_model_1(window_size, dropout_rate, size_vocab, size_lstm)\n",
    "        #model = fit_model(model, X_train, y_train, X_test, y_test, batch_size, epochs, name, callbacks)\n",
    "\n",
    "    elif which == 2:\n",
    "        name = 'lstm_model_2'+name_param\n",
    "        model = lstm_model_2(window_size, dropout_rate, size_vocab, size_lstm)\n",
    "        #model = fit_model(model, X_train, y_train, X_test, y_test, batch_size, epochs, name, callbacks)\n",
    "\n",
    "    elif which == 3:\n",
    "        name = 'lstm_att_model'+name_param\n",
    "        model = lstm_attention_model(window_size, dropout_rate, size_vocab, size_lstm)\n",
    "        #model = fit_model(model, X_train, y_train, X_test, y_test, batch_size, epochs, name, callbacks)\n",
    "\n",
    "    else:\n",
    "        return print(\"No corresponding model\")\n",
    "\n",
    "    return model\n",
    "\n",
    "def get_dataset(file, frequency, window_size):\n",
    "    \n",
    "    data_elements = read_midi_dataset(file)\n",
    "    data_filtered = select_notes(data_elements, frequency=frequency)\n",
    "    \n",
    "    unique_data = list(sorted(set(from_ndarrays_to_list(data_filtered))))\n",
    "    from_ind_to_element = dict((nb, element) for nb, element in enumerate(unique_data)) # from element to integer\n",
    "    \n",
    "    X, y = create_dataset(data_filtered, window_size)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test, dict_vocabulary, size_vocab = dataset_for_NN(X, y, data_filtered,\n",
    "                                                                                   split_ratio=0.2)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, dict_vocabulary, size_vocab, from_ind_to_element\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # PARAMETERS\n",
    "    file = \"/home/cj/Bureau/Master2/Q2/deep_learning/project/Midi_database/*.mid\"\n",
    "    \n",
    "    frequency = 0\n",
    "    window_size = 100 # [32, 64, 100] => last to test\n",
    "    dropout_rate = 0.3 # [0, 0.2, 0.4, 0.8] => second to test\n",
    "    batch_size = 64  # [128, 256, 512, 1024] => third to test\n",
    "    epochs = 200\n",
    "    which = 3\n",
    "    \n",
    "    size_lstm = 512\n",
    "    #size_lstm = [64, 128, 256, 512] # first to test\n",
    "    #name_param = ['_size_64', '_size_128', '_size_256', '_size_512']\n",
    "    \n",
    "    X_train, X_test, y_train, y_test, dict_vocabulary, size_vocab, from_ind_to_element = get_dataset(file, frequency, window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(size_lstm)):\n",
    "        model = get_model(which, window_size, dropout_rate, size_vocab, X_train, y_train, X_test, y_test,\n",
    "                         size_lstm[i], batch_size, epochs, name_param[i], callbacks=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genererate music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded and compiled !\n",
      "full_model_2_classique_3.51_5.mid downloaded succesfully !\n"
     ]
    }
   ],
   "source": [
    "def generate_music(model, nb_steps, dict_vocabulary, input_sequence, size_vocab):\n",
    "    prediction_output = []\n",
    "    for note in range(nb_steps):\n",
    "        prediction_input = np.reshape(input_sequence, (1, len(input_sequence), 1))\n",
    "        prediction_input = prediction_input/float(size_vocab) # normalization\n",
    "        pred = model.predict(prediction_input, verbose=0)\n",
    "        indice = np.argmax(pred) # takes the biggest probability\n",
    "        note_generated = dict_vocabulary[indice]\n",
    "        prediction_output.append(note_generated)\n",
    "        # The note generated is put at the end of the input sequence\n",
    "        input_sequence = np.append(input_sequence, indice)\n",
    "        # The first note is removed from the input sequence\n",
    "        input_sequence = input_sequence[1:len(input_sequence)]\n",
    "\n",
    "    return prediction_output\n",
    "\n",
    "def from_notes_to_MIDI(music_generated, name, tempo):\n",
    "    \n",
    "    offset = 0\n",
    "    output_notes = []\n",
    "    # create note and chord objects based on the values generated by the model\n",
    "    for pattern in music_generated:\n",
    "        \n",
    "        # pattern is a chord\n",
    "        if ('.' in pattern) or pattern.isdigit():\n",
    "            notes_in_chord = pattern.split('.')\n",
    "            notes = []\n",
    "            for current_note in notes_in_chord:\n",
    "                \n",
    "                cn=int(current_note)\n",
    "                new_note = note.Note(cn)\n",
    "                new_note.storedInstrument = instrument.Piano()\n",
    "                notes.append(new_note)\n",
    "                \n",
    "            new_chord = chord.Chord(notes)\n",
    "            new_chord.offset = offset\n",
    "            output_notes.append(new_chord)\n",
    "            \n",
    "        elif('rest' in pattern):\n",
    "            new_rest = note.Rest(pattern)\n",
    "            new_rest.offset = offset\n",
    "            new_rest.storedInstrument = instrument.Piano() #???\n",
    "            output_notes.append(new_rest)\n",
    "            \n",
    "        # pattern is a note\n",
    "        else:\n",
    "            new_note = note.Note(pattern)\n",
    "            new_note.offset = offset\n",
    "            new_note.storedInstrument = instrument.Piano()\n",
    "            output_notes.append(new_note)\n",
    "\n",
    "        # increase offset each iteration so that notes do not stack\n",
    "        offset += tempo\n",
    "    \n",
    "    midi_stream = stream.Stream(output_notes)\n",
    "    name_song = name+'.mid'\n",
    "    midi_stream.write('midi', fp=name_song)\n",
    "    print(name_song+\" downloaded succesfully !\")\n",
    "\n",
    "def get_music(file, model, nb_steps, from_ind_to_element, input_sequence, size_vocab, name_song):\n",
    "    \n",
    "    if file[-2:] == 'f5':\n",
    "        model.load_weights(file)\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "        print('Model loaded and compiled !')\n",
    "    elif file[-2:] == 'h5':\n",
    "        model = load_model(file_model)\n",
    "        print('Model loaded')\n",
    "    else:\n",
    "        print(file[-2:])\n",
    "        return print('Type of file not supported.')\n",
    "    \n",
    "    music_generated = generate_music(model, nb_steps, from_ind_to_element, input_sequence, size_vocab)\n",
    "    tempo = 0.5\n",
    "    from_notes_to_MIDI(music_generated, name_song, tempo)\n",
    "    return music_generated\n",
    "        \n",
    "        \n",
    "        \n",
    "if __name__ == \"__main__\":  \n",
    "    \n",
    "    model = get_model(which, window_size, dropout_rate, size_vocab, X_train, y_train, X_test, y_test,\n",
    "                             size_lstm, batch_size, epochs, '_model_2_allsongs', callbacks=False)\n",
    "    \n",
    "    file = \"/home/cj/Téléchargements/model_results/lstm_2_classique/weights-improvement-25-3.5158-bigger.hdf5\"\n",
    "    ind = np.random.randint(0, len(X_test)-1)\n",
    "    input_sequence = X_test[ind]\n",
    "    nb_steps = 100\n",
    "    name_song = 'full_model_2_classique_3.51_5'\n",
    "    music_generated = get_music(file, model, nb_steps, from_ind_to_element, input_sequence, size_vocab, name_song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('rstudio': conda)",
   "language": "python",
   "name": "python37464bitrstudioconda85139be567af4fb89143852fd1a4ee46"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
